{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA ORGANIZATION**\n",
    "\n",
    "this script will be used for organizing the data/feature engineering and writing other .csv/xslx files as needed\n",
    "\n",
    "NOTE: the orginal datafile will not be saved in this repository as it contains confidential location information...each location will be assigned a number, and we will keep track of this list internally, however this number will not be used in the algorithms as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and get raw data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import funcs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#note that 'private_name' is the associated secret number for the different locations\n",
    "df = pd.read_csv('../data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT NOTES/ASSUMPTIONS: \n",
    "\n",
    "- many of the tests are for other soil/water parameters (pH, electrical conductivity, etc) so we want to extract just pesticide tests...\n",
    "\n",
    "- to be thorough, the DEC tested for numerous pesticides on each sample, many of which were not applied, resulting in lots of important \n",
    "  but unusable data where there is no detectable amount\n",
    "\n",
    "- many farmers/pesticide appliers provided us information on which pesticides they used...the df includes a 'wasused' column that will be\n",
    "  utilized to extract the usable feature...however many pesticides were detectable in cases where we did not know if it was applied, so it\n",
    "  is ASSUMED that the pesticide was applied somewhere in close proximity\n",
    "\n",
    "- different testing methods with different detection limits are used for different pesticides...these methods/limits are often improving it... \n",
    "  is suspected that the lower the detection limit, the more likely a pesticide is to be detected...so it will be used as a parameter in \n",
    "  the algorithms...some detection limits for the associated 'parameter' were not entered into the dataset for each test, however they were all entered for\n",
    "  at least one test, so we must fill the NaN values correctly\n",
    "  \n",
    "- all tests for sulfur as the parameter will be removed due to wildly varying behavior\n",
    "\n",
    "- uninterested in loctype 'Pond', 'Categorical - potable', and 'Long term' as these were ancillary tests or not enough information \n",
    "  is known about the testing area\n",
    "\n",
    "- FEATURE ENGINEERING: all nan results are considered zero...the pesticide was not detected\n",
    "\n",
    "'''\n",
    "# fill na results to 0\n",
    "df['result'] = df['result'].fillna(0)\n",
    "pd.to_numeric(df['result'])\n",
    "\n",
    "# fill all detection limits\n",
    "df['detlimit'].fillna(0, inplace =True)\n",
    "df['detlimit'] = df['detlimit'].astype(str)\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('*',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('>',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('<',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('?',''))\n",
    "df['detlimit'] = df['detlimit'].astype(float)\n",
    "for idx, row in df.iterrows():\n",
    "    # find unfilled detlimit\n",
    "    if row['detlimit'] == '':\n",
    "        parameter = row['parameter']\n",
    "        detlimit = df[(df['detlimit'] != '') & (df['parameter'] == parameter)]\n",
    "\n",
    "        # fill limit if found elsewhere\n",
    "        if len(detlimit) > 0:\n",
    "            df.loc[idx, 'detlimit'] = detlimit.loc[detlimit.index[0],'detlimit']\n",
    "\n",
    "\n",
    "#this contains all test rows to be put into algorithms\n",
    "df_tests = df[np.logical_or(df['wasused'] != 'no', df['koc'].notnull() & df['result'] > 0, df['kfoc'].notnull() & df['result'] > 0)]\n",
    "df_tests = df_tests[df_tests['drainage_class'].notnull() & df_tests['soil_halflife'].notnull()]\n",
    "df_tests = df_tests[df_tests['parameter'] != 'Sulfur']\n",
    "\n",
    "#strip whitespaces\n",
    "df_tests['loctype'] = df_tests['loctype'].apply(lambda x: x.strip())\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Pond']\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Categorical - potable']\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Long term']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT\n",
    "\n",
    "- theoretically, the organic carbon-water partition coefficient ('koc' column) and the organic carbon-water normalized Freundlich distribution \n",
    "  coefficient will be treated as the same\n",
    "\n",
    "- this loop combines the columns, choosing koc first if it is available\n",
    "\n",
    "'''\n",
    "pcoef = []\n",
    "for idx, row in df_tests.iterrows():\n",
    "    if row['koc'] > 0 :\n",
    "        pcoef += [float(row['koc'])]\n",
    "    else :\n",
    "        pcoef += [float(row['kfoc'])]\n",
    "\n",
    "df_tests['pcoef'] = pcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- extract all current columns of potential interest to be put into algorithms...NOT FINAL\n",
    "\n",
    "- other minor fixes\n",
    "'''\n",
    "col_list = ['private_name', 'loctype', 'aquifer_vulnerability', 'drainage_class', 'detlimit', 'sampdate', 'parameter', 'soil_halflife', 'simphalflife', 'morehalflives', 'pcoef', 'simpsorp', 'simpsorp2', 'result', 'simpresult']\n",
    "\n",
    "#get all columns of interest\n",
    "df_cols = df_tests.loc[:, col_list]\n",
    "\n",
    "#replace all instances of 'well drained' to 'Well drained'\n",
    "df_cols.replace(to_replace='well drained', value='Well drained', inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df_reset = df_cols.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT:\n",
    "\n",
    "- at many testing sites, samples were taken in both the downgradient and upgradient groundwater of the pesticide-treated area...\n",
    "  these are distinguished by 'Categorical - upgradient' and'Categorical - downgradiet'...'Categorical - up and downgradient' indicates\n",
    "  one site where the test was both upgradient of one treated area and downgradient of another\n",
    "\n",
    "- tests were done at upgradient sites to find out if pesticides were in the already in the groundwater NOT as a result of the land-owners'\n",
    "  application...this could be the result of a neighboring property apply pesticides, for example...if the same pesticide is detected downgradient \n",
    "  and upgradient of the pesticide application area, then the upgradient value should be subtracted from the downgradient value to get a better\n",
    "  representation of what is happening with land-owners' pesticides\n",
    "\n",
    "- this loop identifies upgradient/downgradient tests on the same sampling date and subtracts the upgradient result from the downgradient\n",
    "\n",
    "'''\n",
    "\n",
    "# BE CAREFUL NOT TO RUN THIS MORE THAN ONCE\n",
    "\n",
    "for idx, row in df_reset.iterrows():\n",
    "    # find 'upgradient' or 'up and downgradient' test on same date for same parameter in same location\n",
    "    if row['loctype'] in ['Categorical - downgradient','Categorical - up and downgradient']:\n",
    "        sampdate = row['sampdate']\n",
    "        parameter = row['parameter']\n",
    "        loctype = row['loctype']\n",
    "        name = row['private_name']\n",
    "        upgradient = df_reset[(df_reset['private_name'] == name) & (df_reset['sampdate'] == sampdate) & (df_reset['loctype'] > loctype) & (df_reset['parameter'] == parameter)]\n",
    "\n",
    "    # if test has both 'upgradient' and 'up and downgradient' samples, then subtract just the 'up and downgradient'\n",
    "    # when upgradient is created, it puts 'up and downgradient' results first, so we can just subtract out first index of whatever upgradient is\n",
    "    if len(upgradient) > 0:\n",
    "      df_reset.loc[idx, 'result'] -= upgradient.loc[upgradient.index[0],'result']\n",
    "\n",
    "# now extract out just the downgradient tests of interests\n",
    "df_adjusted = df_reset[(df_reset['loctype'] != 'Categorical - upgradient') & (df_reset['loctype'] != 'Categorical - up and downgradient') ]\n",
    "\n",
    "\n",
    "# add a 'detected' column if result > 0\n",
    "# 1 if detected, -1 if not\n",
    "for idx, row in df_adjusted.iterrows():\n",
    "    if df_adjusted.loc[idx, 'result'] > 0:\n",
    "        df_adjusted.loc[idx, 'detected'] = 1\n",
    "    else:\n",
    "        df_adjusted.loc[idx, 'detected'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (406) does not match length of index (504)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/n7d1lkjj6y1_lcp76m8nrtbh0000gn/T/ipykernel_82957/3391268652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#append offset and re-add detected column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_adjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detected'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_adjusted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detected'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \"\"\"\n\u001b[0;32m-> 3832\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m         if (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4538\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4539\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (406) does not match length of index (504)"
     ]
    }
   ],
   "source": [
    "#setup final dataframe\n",
    "#for now, working with all raw numbers and not pre-decided categories\n",
    "onehot_cols = ['aquifer_vulnerability', 'drainage_class']\n",
    "raw_cols = ['detlimit','soil_halflife', 'pcoef']\n",
    "\n",
    "#normalize raw values\n",
    "norm = scaler.fit_transform(df_adjusted.loc[:, raw_cols])\n",
    "norm = round(pd.DataFrame(norm, columns = raw_cols), 3)\n",
    "\n",
    "#onehot categorical\n",
    "df_onehot = funcs.onehot(df=df_adjusted, columns = onehot_cols)\n",
    "df_final = pd.concat([df_onehot, norm], axis = 1)\n",
    "\n",
    "#append offset and re-add detected column\n",
    "df_final['offset'] = np.ones((df_adjusted.shape[0]))\n",
    "df_final['detected'] = df_adjusted['detected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write df_final as csv for future use\n",
    "df_final.to_csv(path_or_buf = '../data/df_final.csv', sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
