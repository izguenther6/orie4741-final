{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA ORGANIZATION** ðŸ§º\n",
    "\n",
    "this script will be used for organizing the data/feature engineering and writing other .csv/xslx files as needed\n",
    "\n",
    "NOTE: the orginal datafile will not be saved in this repository as it contains confidential location information...each location will be assigned a number, and we will keep track of this list internally, however this number will not be used in the algorithms as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and get raw data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import funcs\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# note that 'private_name' is the associated secret number for the different locations\n",
    "# df is importated from local machine to protect privacy\n",
    "df = pd.read_csv('/Users/isaiah/Desktop/swl/nys pesticides/data/raw_data.csv')\n",
    "df2 = pd.read_csv('/Users/isaiah/Desktop/swl/nys pesticides/data/raw_data.csv')\n",
    "t1 = pd.read_excel('../data/table1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/n7d1lkjj6y1_lcp76m8nrtbh0000gn/T/ipykernel_20580/2045444420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detlimit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detlimit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# fill all detection limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detlimit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nan'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m def _sanitize_ndim(\n\u001b[0m\u001b[1;32m    631\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "IMPORTANT NOTES/ASSUMPTIONS: \n",
    "\n",
    "- many of the tests are for other soil/water parameters (pH, electrical conductivity, etc) so we want to extract just pesticide tests...\n",
    "\n",
    "- to be thorough, the DEC tested for numerous pesticides on each sample, many of which were not applied, resulting in lots of important \n",
    "  but unusable data where there is no detectable amount\n",
    "\n",
    "- many farmers/pesticide appliers provided us information on which pesticides they used...the df includes a 'wasused' column that will be\n",
    "  utilized to extract the usable feature...however many pesticides were detectable in cases where we did not know if it was applied, so it\n",
    "  is ASSUMED that the pesticide was applied somewhere in close proximity\n",
    "\n",
    "- different testing methods with different detection limits are used for different pesticides...these methods/limits are often improving it... \n",
    "  is suspected that the lower the detection limit, the more likely a pesticide is to be detected...so it will be used as a parameter in \n",
    "  the algorithms...some detection limits for the associated 'parameter' were not entered into the dataset for each test, however they were all entered for\n",
    "  at least one test, so we must fill the NaN values correctly\n",
    "  \n",
    "- all tests for sulfur as the parameter will be removed due to wildly varying behavior\n",
    "\n",
    "- uninterested in loctype 'Pond', 'Categorical - potable', and 'Long term' as these were ancillary tests or not enough information \n",
    "  is known about the testing area\n",
    "\n",
    "- FEATURE ENGINEERING: all nan results are considered zero...the pesticide was not detected\n",
    "\n",
    "'''\n",
    "# fill na results to 0\n",
    "df['result'] = df['result'].fillna(0)\n",
    "pd.to_numeric(df['result'])\n",
    "\n",
    "df['detlimit'] = df['detlimit'].astype(str)\n",
    "# fill all detection limits\n",
    "for idx, row in df.iterrows():\n",
    "    if row['detlimit'] == 'nan':\n",
    "        parameter = row['parameter']\n",
    "        detlimit = df[(df['detlimit'] != 'nan') & (df['parameter'] == parameter)]\n",
    "\n",
    "        # fill limit if found elsewhere\n",
    "        if len(detlimit) > 0:\n",
    "            year = row['sampdate'][0:4]\n",
    "            for idx2, row2 in detlimit.iterrows():\n",
    "                if row2['sampdate'][0:4] == year:\n",
    "                    df.loc[idx, 'detlimit'] = detlimit.loc[idx2,'detlimit']\n",
    "                    break\n",
    "\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('*',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('>',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('<',''))\n",
    "df['detlimit'] = df['detlimit'].apply(lambda x: x.replace('?',''))\n",
    "df['detlimit'] = df['detlimit'].astype(float)\n",
    "\n",
    "#this contains all test rows to be put into algorithms\n",
    "df_tests = df[np.logical_or(df['wasused'] != 'no', df['koc'].notnull() & df['result'] > 0, df['kfoc'].notnull() & df['result'] > 0)]\n",
    "df_tests = df_tests[df_tests['drainage_class'].notnull() & df_tests['soil_halflife'].notnull()]\n",
    "df_tests = df_tests[df_tests['parameter'] != 'Sulfur']\n",
    "\n",
    "#strip whitespaces\n",
    "df_tests['loctype'] = df_tests['loctype'].apply(lambda x: x.strip())\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Pond']\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Categorical - potable']\n",
    "df_tests = df_tests[df_tests['loctype'] != 'Long term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boscalid' 'Myclobutanil' 'Chlorpyrifos' 'Oxadiazon' 'Metolachlor OA'\n",
      " 'Metolachlor ESA' 'Fluopyram' 'Imidacloprid' 'Indaziflam' 'Atrazine'\n",
      " 'Linuron' 'S-Metolachlor' 'Carbaryl' 'Flumioxazin' 'Glyphosate'\n",
      " 'Ethofumesate' 'Acetamiprid' 'Malathion' 'Metribuzin' 'Sulfentrazone'\n",
      " 'Terbacil' 'Diuron' 'Acetochlor ESA' 'Simazine' 'Tebuconazole'\n",
      " 'Thiamethoxam' 'Mandipropamid' 'Clethodim' 'JSE76' 'Mefentrifluconazole'\n",
      " 'Pyrimethanil' 'Iprodione' 'Propiconazole' 'Bentazon'\n",
      " 'Chlorantraniliprole' 'Fluazinam' 'Fluxapyroxad' 'Paclobutrazol'\n",
      " 'Clopyralid' 'Dithiopyr' 'Halosulfuron-methyl' 'Triadimefon'\n",
      " 'De Ethyl Atrazine' '2,4-D' 'Dicamba']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(df_tests.loc[:,'parameter'].unique())\n",
    "print(len(df_tests.loc[:,'parameter'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT\n",
    "\n",
    "- theoretically, the organic carbon-water partition coefficient ('koc' column) and the organic carbon-water normalized Freundlich distribution \n",
    "  coefficient will be treated as the same\n",
    "\n",
    "- this loop combines the columns, choosing koc first if it is available\n",
    "\n",
    "'''\n",
    "pcoef = []\n",
    "for idx, row in df_tests.iterrows():\n",
    "    if row['koc'] > 0 :\n",
    "        pcoef += [float(row['koc'])]\n",
    "    else :\n",
    "        pcoef += [float(row['kfoc'])]\n",
    "\n",
    "df_tests['pcoef'] = pcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- extract all current columns of potential interest to be put into algorithms...NOT FINAL\n",
    "\n",
    "- other minor fixes\n",
    "'''\n",
    "col_list = ['private_name', 'loctype', 'aquifer_vulnerability', 'drainage_class', 'detlimit', 'sampdate', 'parameter','gus', 'soil_halflife', 'simphalflife', 'morehalflives', 'pcoef', 'simpsorp', 'simpsorp2', 'result', 'simpresult']\n",
    "\n",
    "#get all columns of interest\n",
    "df_cols = df_tests.loc[:, col_list]\n",
    "\n",
    "#replace all instances of 'well drained' to 'Well drained'\n",
    "df_cols.replace(to_replace='well drained', value='Well drained', inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT:\n",
    "\n",
    "- at many testing sites, samples were taken in both the downgradient and upgradient groundwater of the pesticide-treated area...\n",
    "  these are distinguished by 'Categorical - upgradient' and'Categorical - downgradient'...'Categorical - up and downgradient' indicates\n",
    "  one site where the test was both upgradient of one treated area and downgradient of another\n",
    "\n",
    "- tests were done at upgradient sites to find out if pesticides were in the already in the groundwater NOT as a result of the land-owners'\n",
    "  application...this could be the result of a neighboring property apply pesticides, for example...if the same pesticide is detected downgradient \n",
    "  and upgradient of the pesticide application area, then the upgradient value should be subtracted from the downgradient value to get a better\n",
    "  representation of what is happening with land-owners' pesticides\n",
    "\n",
    "- this loop identifies upgradient/downgradient tests on the same sampling date and subtracts the upgradient result from the downgradient\n",
    "\n",
    "'''\n",
    "\n",
    "# reset index\n",
    "df_reset = df_cols.reset_index().iloc[:,1:]\n",
    "\n",
    "for idx, row in df_reset.iterrows():\n",
    "    # find 'upgradient' or 'up and downgradient' test on same date for same parameter in same location\n",
    "    if row['loctype'] in ['Categorical - downgradient','Categorical - up and downgradient']:\n",
    "        sampdate = row['sampdate']\n",
    "        parameter = row['parameter']\n",
    "        loctype = row['loctype']\n",
    "        name = row['private_name']\n",
    "        upgradient = df_reset[(df_reset['private_name'] == name) & (df_reset['sampdate'] == sampdate) & (df_reset['loctype'] > loctype) & (df_reset['parameter'] == parameter)]\n",
    "\n",
    "    # if test has both 'upgradient' and 'up and downgradient' samples, then subtract just the 'up and downgradient'\n",
    "    # when upgradient is created, it puts 'up and downgradient' results first, so we can just subtract out first index of whatever upgradient is\n",
    "    if len(upgradient) > 0:\n",
    "      df_reset.loc[idx, 'result'] -= upgradient.loc[upgradient.index[0],'result']\n",
    "\n",
    "# now extract out just the downgradient tests of interests\n",
    "# UNDECIDED ON THIS! for now just copy df_reset\n",
    "#df_adjusted = df_reset[(df_reset['loctype'] != 'Categorical - upgradient') & (df_reset['loctype'] != 'Categorical - up and downgradient') ]\n",
    "df_adjusted = df_reset.loc[:,:]\n",
    "\n",
    "# add a 'detected' column if result > 0\n",
    "# 1 if detected, -1 if not\n",
    "for idx, row in df_adjusted.iterrows():\n",
    "    if df_adjusted.loc[idx, 'result'] > 0:\n",
    "        df_adjusted.loc[idx, 'detected'] = 1\n",
    "    else:\n",
    "        df_adjusted.loc[idx, 'detected'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index again\n",
    "df_adjusted = df_adjusted.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT\n",
    "\n",
    "- SWL lab members are currently deriving a new theoretical groundwater ubiquity score (TGUS) to be compared to typically used groundwater ubiquity\n",
    "  score (GUS) derived by Gustafson et al., 1989\n",
    "\n",
    "- dataframe 't1' contains columns for the GUS, TGUS, and TGUS* (a modified form of TGUS) for 45 different pesticides, as well as some more accurate\n",
    "  soil halflife and partitioning coefficient values that need to be updated in our data\n",
    "\n",
    "- we will consider the effect of all ubiquity scores together and separately for predicting test outcomes\n",
    "\n",
    "- many tgus and tgus* values are not documented, so those need to be calculated using defined functions\n",
    "\n",
    "'''\n",
    "for idx, row in df_adjusted.iterrows():\n",
    "  parameter = row['parameter']\n",
    "\n",
    "  if parameter in t1['parameter'].unique():\n",
    "    # get needed values from t1\n",
    "    pcoef = t1[t1['parameter'] == parameter]['koc']\n",
    "    shl = t1[t1['parameter'] == parameter]['soil_halflife']\n",
    "    gus = t1[t1['parameter'] == parameter]['gus']\n",
    "    tgus = t1[t1['parameter'] == parameter]['tgus']\n",
    "    tgus_star = t1[t1['parameter'] == parameter]['tgus*']\n",
    "\n",
    "    # add values to data\n",
    "    df_adjusted.loc[idx, 'pcoef'] = pcoef.iloc[0]\n",
    "    df_adjusted.loc[idx, 'soil_halflife'] = shl.iloc[0]\n",
    "    df_adjusted.loc[idx, 'gus'] = gus.iloc[0]\n",
    "    df_adjusted.loc[idx, 'tgus'] = tgus.iloc[0]\n",
    "    df_adjusted.loc[idx, 'tgus*'] = tgus_star.iloc[0]\n",
    "\n",
    "  else:\n",
    "    tgus_star = funcs.tgus(row['soil_halflife'], row['pcoef'], star = True)\n",
    "    tgus = funcs.tgus(row['soil_halflife'], row['pcoef'])\n",
    "    df_adjusted.loc[idx, 'tgus*'] = tgus_star\n",
    "    df_adjusted.loc[idx, 'tgus'] = tgus\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup final dataframe\n",
    "# for now, working with all raw numbers and not pre-decided categories\n",
    "onehot_cols = ['aquifer_vulnerability','drainage_class']\n",
    "raw_cols = ['gus','tgus','soil_halflife', 'pcoef','detlimit']\n",
    "\n",
    "# normalize raw values\n",
    "norm = scaler.fit_transform(df_adjusted.loc[:, raw_cols])\n",
    "norm = round(pd.DataFrame(norm, columns = raw_cols), 3)\n",
    "\n",
    "# onehot categorical\n",
    "df_onehot = funcs.onehot(df=df_adjusted, columns = onehot_cols)\n",
    "df_final = pd.concat([df_onehot, norm], axis = 1)\n",
    "\n",
    "# append offset and re-add detected column\n",
    "df_final['offset'] = np.ones((df_adjusted.shape[0]))\n",
    "df_final['detected'] = df_adjusted['detected']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT CONCEPT\n",
    "\n",
    "- to compare the performance of the different groundwater ubiquity score, values, we will make separate dataframes containing just one of the score values\n",
    "\n",
    "- we will also separate out a dataframe with just the soil halflives/partitioning coefficient and no ubiquity scores to see how well raw values perform\n",
    "\n",
    "- 'df_final' will be used to evaluate the performance of all ubiquity scores and raw data combined\n",
    "\n",
    "'''\n",
    "\n",
    "df_gus = df_final.loc[:, ~df_final.columns.isin(['tgus', 'tgus*', 'soil_halflife', 'pcoef'])]\n",
    "df_tgus = df_final.loc[:, ~df_final.columns.isin(['gus', 'tgus*', 'soil_halflife', 'pcoef'])]\n",
    "df_tgus_st = df_final.loc[:, ~df_final.columns.isin(['tgus', 'gus', 'soil_halflife', 'pcoef'])]\n",
    "df_raw = df_final.loc[:, ~df_final.columns.isin(['tgus', 'tgus*', 'gus'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write df_final as csv for future use\n",
    "df_final.to_csv(path_or_buf = '../data/df_all.csv', sep = ',')\n",
    "df_gus.to_csv(path_or_buf = '../data/df_gus.csv', sep = ',')\n",
    "df_tgus.to_csv(path_or_buf = '../data/df_tgus.csv', sep = ',')\n",
    "df_tgus_st.to_csv(path_or_buf = '../data/df_tgus*.csv', sep = ',')\n",
    "df_raw.to_csv(path_or_buf = '../data/df_raw.csv', sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
