{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SUPPORT VECTOR CLASSIFIER** ðŸ›ï¸\n",
    "\n",
    "this script is for setup, execution, and evaluation of the support vector classifier algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import funcs as f\n",
    "import scipy.stats as sts\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set clf, import data from data_organization.ipynb, and set random seed\n",
    "'''\n",
    "clf = SVC(kernel='poly', C=.1, gamma=10)\n",
    "\n",
    "df_all = pd.read_csv('../data/df_all.csv').drop('Unnamed: 0', axis = 1)\n",
    "df_gus = pd.read_csv('../data/df_gus.csv').drop('Unnamed: 0', axis = 1)\n",
    "df_tgus = pd.read_csv('../data/df_tgus.csv').drop('Unnamed: 0', axis = 1)\n",
    "df_tgus_st = pd.read_csv('../data/df_tgus*.csv').drop('Unnamed: 0', axis = 1)\n",
    "df_raw = pd.read_csv('../data/df_raw.csv').drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All - Results:\n",
      "Best Scenario Training Accuracy: 99.0%\n",
      "Average Training Accuracy: 99.7%\n",
      "Best Scenario Validation Accuracy: 100.0%\n",
      "Average Validation Accuracy: 99.2%\n",
      "Best Scenario Test Accuracy: 100.0%\n",
      "Average Test Accuracy: 96.9%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Considering GUS, TGUS,  TGUS*, and raw values with other features\n",
    "\n",
    "'''\n",
    "all_train =[]\n",
    "all_vals =[]\n",
    "all_tests=[]\n",
    "for i in range(100):\n",
    "    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_all, clf, 'svc')\n",
    "    all_train = np.append(train_acc, all_train)\n",
    "    all_vals = np.append(val_acc, all_vals)\n",
    "    all_tests = np.append(test_acc, all_tests)\n",
    "\n",
    "    # keep best model\n",
    "    if test_acc >= np.max(all_tests):\n",
    "        all_model = model\n",
    "        all_train_acc = train_acc\n",
    "        all_val_acc = val_acc\n",
    "        all_test_acc = test_acc\n",
    "\n",
    "print('All - Results:')\n",
    "print(f'Best Scenario Training Accuracy: {all_train_acc}%')\n",
    "print(f'Average Training Accuracy: {round(np.mean(all_train),1)}%')\n",
    "print(f'Best Scenario Validation Accuracy: {all_val_acc}%')\n",
    "print(f'Average Validation Accuracy: {round(np.mean(all_vals),1)}%')\n",
    "print(f'Best Scenario Test Accuracy: {all_test_acc}%')\n",
    "print(f'Average Test Accuracy: {round(np.mean(all_tests),1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests[all_tests == 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUS - Results:\n",
      "Best Scenario Training Accuracy: 99.0%\n",
      "Average Training Accuracy: 99.2%\n",
      "Best Scenario Validation Accuracy: 100.0%\n",
      "Average Validation Accuracy: 98.9%\n",
      "Best Scenario Test Accuracy: 100.0%\n",
      "Average Test Accuracy: 96.4%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Considering just GUS with other features\n",
    "\n",
    "'''\n",
    "gus_train =[]\n",
    "gus_vals =[]\n",
    "gus_tests=[]\n",
    "for i in range(100):\n",
    "    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_gus, clf, 'svc')\n",
    "    gus_train = np.append(train_acc, gus_train)\n",
    "    gus_vals = np.append(val_acc, gus_vals)\n",
    "    gus_tests = np.append(test_acc, gus_tests)\n",
    "\n",
    "    # keep best model\n",
    "    if test_acc >= np.max(gus_tests):\n",
    "        gus_model = model\n",
    "        gus_train_acc = train_acc\n",
    "        gus_val_acc = val_acc\n",
    "        gus_test_acc = test_acc\n",
    "\n",
    "print('GUS - Results:')\n",
    "print(f'Best Scenario Training Accuracy: {gus_train_acc}%')\n",
    "print(f'Average Training Accuracy: {round(np.mean(gus_train),1)}%')\n",
    "print(f'Best Scenario Validation Accuracy: {gus_val_acc}%')\n",
    "print(f'Average Validation Accuracy: {round(np.mean(gus_vals),1)}%')\n",
    "print(f'Best Scenario Test Accuracy: {gus_test_acc}%')\n",
    "print(f'Average Test Accuracy: {round(np.mean(gus_tests),1)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGUS - Results:\n",
      "Best Scenario Training Accuracy: 99.0%\n",
      "Average Training Accuracy: 98.9%\n",
      "Best Scenario Validation Accuracy: 98.6%\n",
      "Average Validation Accuracy: 99.2%\n",
      "Best Scenario Test Accuracy: 100.0%\n",
      "Average Test Accuracy: 96.8%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Considering just TGUS with other features\n",
    "\n",
    "'''\n",
    "tgus_train =[]\n",
    "tgus_vals =[]\n",
    "tgus_tests=[]\n",
    "for i in range(100):\n",
    "    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_tgus, clf, 'svc')\n",
    "    tgus_train = np.append(train_acc, tgus_train)\n",
    "    tgus_vals = np.append(val_acc, tgus_vals)\n",
    "    tgus_tests = np.append(test_acc, tgus_tests)\n",
    "\n",
    "    # keep best model\n",
    "    if test_acc >= np.max(tgus_tests):\n",
    "        tgus_model = model\n",
    "        tgus_train_acc = train_acc\n",
    "        tgus_val_acc = val_acc\n",
    "        tgus_test_acc = test_acc\n",
    "\n",
    "print('TGUS - Results:')\n",
    "print(f'Best Scenario Training Accuracy: {tgus_train_acc}%')\n",
    "print(f'Average Training Accuracy: {round(np.mean(tgus_train),1)}%')\n",
    "print(f'Best Scenario Validation Accuracy: {tgus_val_acc}%')\n",
    "print(f'Average Validation Accuracy: {round(np.mean(tgus_vals),1)}%')\n",
    "print(f'Best Scenario Test Accuracy: {tgus_test_acc}%')\n",
    "print(f'Average Test Accuracy: {round(np.mean(tgus_tests),1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConsidering just TGUS* and raw values with other features\\n\\n\\ntgus_st_train =[]\\ntgus_st_vals =[]\\ntgus_st_tests=[]\\nfor i in range(30):\\n    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_tgus_st, clf, 'svc')\\n    tgus_st_train = np.append(train_acc, tgus_st_train)\\n    tgus_st_vals = np.append(val_acc, tgus_st_vals)\\n    tgus_st_tests = np.append(test_acc, tgus_st_tests)\\n\\n    # keep best model\\n    if test_acc >= np.max(tgus_st_tests):\\n        tgus_st_model = model\\n        tgus_st_train_acc = train_acc\\n        tgus_st_val_acc = val_acc\\n        tgus_st_test_acc = test_acc\\n\\nprint('TGUS* - Results:')\\nprint(f'Best Scenario Training Accuracy: {tgus_st_train_acc}%')\\nprint(f'Average Training Accuracy: {round(np.mean(tgus_st_train),1)}%')\\nprint(f'Best Scenario Validation Accuracy: {tgus_st_val_acc}%')\\nprint(f'Average Validation Accuracy: {round(np.mean(tgus_st_vals),1)}%')\\nprint(f'Best Scenario Test Accuracy: {tgus_st_test_acc}%')\\nprint(f'Average Test Accuracy: {round(np.mean(tgus_st_tests),1)}%')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Considering just TGUS* and raw values with other features\n",
    "\n",
    "\n",
    "tgus_st_train =[]\n",
    "tgus_st_vals =[]\n",
    "tgus_st_tests=[]\n",
    "for i in range(30):\n",
    "    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_tgus_st, clf, 'svc')\n",
    "    tgus_st_train = np.append(train_acc, tgus_st_train)\n",
    "    tgus_st_vals = np.append(val_acc, tgus_st_vals)\n",
    "    tgus_st_tests = np.append(test_acc, tgus_st_tests)\n",
    "\n",
    "    # keep best model\n",
    "    if test_acc >= np.max(tgus_st_tests):\n",
    "        tgus_st_model = model\n",
    "        tgus_st_train_acc = train_acc\n",
    "        tgus_st_val_acc = val_acc\n",
    "        tgus_st_test_acc = test_acc\n",
    "\n",
    "print('TGUS* - Results:')\n",
    "print(f'Best Scenario Training Accuracy: {tgus_st_train_acc}%')\n",
    "print(f'Average Training Accuracy: {round(np.mean(tgus_st_train),1)}%')\n",
    "print(f'Best Scenario Validation Accuracy: {tgus_st_val_acc}%')\n",
    "print(f'Average Validation Accuracy: {round(np.mean(tgus_st_vals),1)}%')\n",
    "print(f'Best Scenario Test Accuracy: {tgus_st_test_acc}%')\n",
    "print(f'Average Test Accuracy: {round(np.mean(tgus_st_tests),1)}%')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw - Results:\n",
      "Best Scenario Training Accuracy: 99.0%\n",
      "Average Training Accuracy: 99.6%\n",
      "Best Scenario Validation Accuracy: 98.6%\n",
      "Average Validation Accuracy: 99.0%\n",
      "Best Scenario Test Accuracy: 100.0%\n",
      "Average Test Accuracy: 96.5%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Considering just raw values with other features\n",
    "\n",
    "'''\n",
    "raw_train =[]\n",
    "raw_vals =[]\n",
    "raw_tests=[]\n",
    "for i in range(100):\n",
    "    model, train_acc, val_acc, test_acc = f.kfold_crossval(df_raw, clf, 'svc')\n",
    "    raw_train = np.append(train_acc, raw_train)\n",
    "    raw_vals = np.append(val_acc, raw_vals)\n",
    "    raw_tests = np.append(test_acc, raw_tests)\n",
    "\n",
    "    # keep best model\n",
    "    if test_acc >= np.max(raw_tests):\n",
    "        raw_model = model\n",
    "        raw_train_acc = train_acc\n",
    "        raw_val_acc = val_acc\n",
    "        raw_test_acc = test_acc\n",
    "\n",
    "print('Raw - Results:')\n",
    "print(f'Best Scenario Training Accuracy: {raw_train_acc}%')\n",
    "print(f'Average Training Accuracy: {round(np.mean(raw_train),1)}%')\n",
    "print(f'Best Scenario Validation Accuracy: {raw_val_acc}%')\n",
    "print(f'Average Validation Accuracy: {round(np.mean(raw_vals),1)}%')\n",
    "print(f'Best Scenario Test Accuracy: {raw_test_acc}%')\n",
    "print(f'Average Test Accuracy: {round(np.mean(raw_tests),1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Equal variance t-tests to compare result means\n",
    "'''\n",
    "cols = ['All', 'GUS', 'TGUS', 'Raw']\n",
    "train_scores = pd.DataFrame({'All': all_train, 'GUS': gus_train, 'TGUS': tgus_train, 'Raw': raw_train})\n",
    "val_scores = pd.DataFrame({'All': all_vals, 'GUS': gus_vals, 'TGUS': tgus_vals, 'Raw': raw_vals})\n",
    "test_scores = pd.DataFrame({'All': all_tests, 'GUS': gus_tests, 'TGUS': tgus_tests, 'Raw': raw_tests})\n",
    "\n",
    "comp_train = pd.DataFrame(columns = train_scores.columns, index = train_scores.columns )\n",
    "comp_val = pd.DataFrame(columns = train_scores.columns, index = train_scores.columns )\n",
    "comp_test = pd.DataFrame(columns = train_scores.columns, index = train_scores.columns )\n",
    "\n",
    "for i in cols:\n",
    "    for j in cols:\n",
    "        stat_train,p_train = sts.ttest_ind(train_scores.loc[:,i], train_scores.loc[:,j], equal_var = True, alternative = 'two-sided')\n",
    "        comp_train.loc[i,j] = [round(p_train,100)]\n",
    "\n",
    "        stat_val,p_val = sts.ttest_ind(val_scores.loc[:,i], val_scores.loc[:,j], equal_var = True, alternative = 'two-sided')\n",
    "        comp_val.loc[i,j] = [round(p_val,100)]\n",
    "\n",
    "        stat_test,p_test = sts.ttest_ind(test_scores.loc[:,i], test_scores.loc[:,j], equal_var = True, alternative = 'two-sided')\n",
    "        comp_test.loc[i,j] = [round(p_test,100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
